---
title: "Optimizing Your Classifier with Utility Functions"
author: "Siddarth Ramesh"
output:
  html_document: default
---

#Overview

1. Quickly build a classifier
2. Extremely high level definition of an ROC curve
3. Definition of utility in economics
4. Learn how to set ROC thresholds based on maximizing utility


#The Use Case

In this use case, imagine you are a movie theater owner. You decide to increase movie ticket sales, you want to build an app to recommend movies to your loyal customers.

The following is the top few rows of a dataset for one customer. 0 means the customer did not like that movie and 1 means the customer did. We are just going to take the ROC curve for this one person and then figure out what the optimal threshold is. 

**Prereqs to run the code**

- Requires `RevoScaleR` package
- `install.packages("tidyverse")`
- `install.packages("pROC")`

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pROC)
```


```{r data, echo = FALSE}

train <- read.csv("train2.csv")
test <- read.csv("test2.csv")
test$Genre1 = factor(test$Genre1, levels(train$Genre1))

head(select(train, original_title, Genre1, rating))
```


#Build a classifier

We'll just use a logistic regression model

```{r classifier, results = "hide"}
form = rating ~ Genre1
model = rxLogit(form, train)

```


```{r prediction, results = "hide"}

prediction <- rxPredict(model, test) 
test_results <- cbind(test, prediction) %>% subset(select = -c(1,2,id, keywords))
```



```{r roc_table}
roc_data <- select(test_results, Genre1, rating, rating_Pred)
roc_data
```


# Evaluate the classifier



### Describing the ROC curve

We have an ROC curve which tells us how well our model can detect if a movie will be liked by a customer or not.


1. **True positive (TP)**: Good movie correctly identified as good
2. **False positive (FP)**: Bad movie incorrectly identified as good
3. **True negative (TN)**: Bad movie correctly identified as bad
4. **False negative (FN)**: Good movie incorrectly identified as bad
5. **Sensitivity**: TP/(TP+FN), true positive rate
6. **Specificity**: TN/(TN+FP), true negative rate
7. **False positive rate** = 1 - specificity

```{r roc}

roc_obj = roc(roc_data$rating, roc_data$rating_Pred)
roc_obj
plot(roc_obj)

```

1. **High sensitivity, low specificity**: Many false positives, top right part of ROC curve
2. **High specificity, low sensitivity**: Many false negatives, bottom left part of ROC curve


The top right part means the model would generate a ton of false positives and recommend movies to the customer that the customer may not like in addition to movies the customer will like. The model is pretty optimistic about all movies.  

The bottom left part means the model would filter out any movies it doesn't remotely think the customer would like, and only give out movies it is certain about it. However, it may fail to recommend movies that a customer might have actually liked! We can say that the model is very picky.

#Utility

**Utility** - an economic term which refers to the satisfaction or benefit a person derives from a good or service

Utility comes in when we want to figure out where we want to set our threshold for our ROC curve. Getting the optimum threshold means finding the threshold on the ROC which maximizes utility. To maximize utility, we need to minimize the cost. 



###From the movie business standpoint

- Failing to recommend a good movie costs $9.00 per customer. In other words, this is setting a cost on high specificities.



```{r costs}
cost1 = 9

cost = cost1*(1-roc_obj$sensitivities)
threshold_cost_table = data.frame(sensitivity = roc_obj$sensitivities, specificity = roc_obj$specificities, cost)
threshold_cost_table[order(threshold_cost_table$cost),]
cost_line = threshold_cost_table[head(order(threshold_cost_table$cost), 1),]%>% select(sensitivity,specificity)
plot(roc_obj) 
points(cost_line$specificity, cost_line$sensitivity, col = "red", pch = 19)
```


Let's assume now that there is a cost to recommending a bad movie - **10.00 dollars**. 

6.00 out of the 10.00 dollars is because 2/3 of your customers aren't interested in your recommendation and don't buy your 9.00 dollar ticket. The other 4.00 dollars happens in case a fraction of them of them tell their friends that the recommendation of your app sucks, so it's the cost of a worse reputation.


```{r costs2}
cost1 = 9
cost2 = 10
cost = cost1*(1-roc_obj$sensitivities) + cost2*(1-roc_obj$specificities)
threshold_cost_table = data.frame(sensitivity = roc_obj$sensitivities, specificity = roc_obj$specificities, cost)
threshold_cost_table[order(threshold_cost_table$cost),]
cost_line = threshold_cost_table[head(order(threshold_cost_table$cost), 1),]%>% select(sensitivity,specificity)
plot(roc_obj) 
points(cost_line$specificity, cost_line$sensitivity, col = "red", pch = 19)
```


###From the User's Standpoint

Let's see what kind of recommendation the app-user would have to maximize his/her utility.

1. The cost of going to the movie is 9 dollars, so going to a bad movie is 9 dollars lost.
2. Each hour of the user is worth 3 dollars, so if the movie was 2 hours on average, this is about 6 dollars.
3. The emotional pain of the user having seen the bad movie is worth 2 more dollars
4. Missing a movie the user would have liked might cost 4 dollars of the emotional struggle of having to deal with all of the user's friends having watched the movie - also known as FOMO.


```{r costs3}
cost1 = 4
cost2 = 9+6+2
cost = cost1*(1-roc_obj$sensitivities) + cost2*(1-roc_obj$specificities)
threshold_cost_table = data.frame(sensitivity = roc_obj$sensitivities, specificity = roc_obj$specificities, cost)
threshold_cost_table[order(threshold_cost_table$cost),]
cost_line = threshold_cost_table[head(order(threshold_cost_table$cost), 1),]%>% select(sensitivity,specificity)
plot(roc_obj) 
points(cost_line$specificity, cost_line$sensitivity, col = "red", pch = 19)
```


Therefore this user would be happy with a recommender of higher specificity, but that isn't in the theater's best interests. 

Credit to http://blog.mldb.ai/blog/posts/2016/01/ml-meets-economics/



